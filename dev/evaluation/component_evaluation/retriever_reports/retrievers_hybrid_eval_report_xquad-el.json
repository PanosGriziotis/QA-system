{
    "1": {
        "BM25Retriever": {
            "recall_multi_hit": 0.0,
            "recall_single_hit": 0.0,
            "precision": 0.0,
            "map": 0.0,
            "mrr": 0.0,
            "ndcg": 0.0
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.0,
            "recall_single_hit": 0.0,
            "precision": 0.0,
            "map": 0.0,
            "mrr": 0.0,
            "ndcg": 0.0
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.0,
            "recall_single_hit": 0.0,
            "precision": 0.0,
            "map": 0.0,
            "mrr": 0.0,
            "ndcg": 0.0
        },
        "Ranker": {
            "recall_multi_hit": 0.0,
            "recall_single_hit": 0.0,
            "precision": 0.0,
            "map": 0.0,
            "mrr": 0.0,
            "ndcg": 0.0
        }
    },
    "2": {
        "BM25Retriever": {
            "recall_multi_hit": 0.8133445945945946,
            "recall_single_hit": 0.8133445945945946,
            "precision": 0.8133445945945946,
            "map": 0.8133445945945946,
            "mrr": 0.8133445945945946,
            "ndcg": 0.8133445945945946
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.41300675675675674,
            "recall_single_hit": 0.41300675675675674,
            "precision": 0.41300675675675674,
            "map": 0.41300675675675674,
            "mrr": 0.41300675675675674,
            "ndcg": 0.41300675675675674
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.8538851351351351,
            "recall_single_hit": 0.8538851351351351,
            "precision": 0.6131756756756757,
            "map": 0.8336148648648649,
            "mrr": 0.8336148648648649,
            "ndcg": 0.8389228278474916
        },
        "Ranker": {
            "recall_multi_hit": 0.8538851351351351,
            "recall_single_hit": 0.8538851351351351,
            "precision": 0.6131756756756757,
            "map": 0.8420608108108109,
            "mrr": 0.8420608108108109,
            "ndcg": 0.8451571225506763
        }
    },
    "3": {
        "BM25Retriever": {
            "recall_multi_hit": 0.8133445945945946,
            "recall_single_hit": 0.8133445945945946,
            "precision": 0.8133445945945946,
            "map": 0.8133445945945946,
            "mrr": 0.8133445945945946,
            "ndcg": 0.8133445945945946
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.41300675675675674,
            "recall_single_hit": 0.41300675675675674,
            "precision": 0.41300675675675674,
            "map": 0.41300675675675674,
            "mrr": 0.41300675675675674,
            "ndcg": 0.41300675675675674
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.8538851351351351,
            "recall_single_hit": 0.8538851351351351,
            "precision": 0.6131756756756757,
            "map": 0.8336148648648649,
            "mrr": 0.8336148648648649,
            "ndcg": 0.8389228278474916
        },
        "Ranker": {
            "recall_multi_hit": 0.8538851351351351,
            "recall_single_hit": 0.8538851351351351,
            "precision": 0.6131756756756757,
            "map": 0.8420608108108109,
            "mrr": 0.8420608108108109,
            "ndcg": 0.8451571225506763
        }
    },
    "4": {
        "BM25Retriever": {
            "recall_multi_hit": 0.8809121621621622,
            "recall_single_hit": 0.8809121621621622,
            "precision": 0.4497466216216216,
            "map": 0.846706081081081,
            "mrr": 0.846706081081081,
            "ndcg": 0.8556632686142636
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.5971283783783784,
            "recall_single_hit": 0.5971283783783784,
            "precision": 0.30574324324324326,
            "map": 0.5050675675675675,
            "mrr": 0.5050675675675675,
            "ndcg": 0.5291745661136636
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9273648648648649,
            "recall_single_hit": 0.9273648648648649,
            "precision": 0.30778434684684686,
            "map": 0.8585069444444444,
            "mrr": 0.8609938063063063,
            "ndcg": 0.8767620037977742
        },
        "Ranker": {
            "recall_multi_hit": 0.9273648648648649,
            "recall_single_hit": 0.9273648648648649,
            "precision": 0.30778434684684686,
            "map": 0.8947541291291291,
            "mrr": 0.8963963963963966,
            "ndcg": 0.9036657365555574
        }
    },
    "5": {
        "BM25Retriever": {
            "recall_multi_hit": 0.8809121621621622,
            "recall_single_hit": 0.8809121621621622,
            "precision": 0.4497466216216216,
            "map": 0.846706081081081,
            "mrr": 0.846706081081081,
            "ndcg": 0.8556632686142636
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.5971283783783784,
            "recall_single_hit": 0.5971283783783784,
            "precision": 0.30574324324324326,
            "map": 0.5050675675675675,
            "mrr": 0.5050675675675675,
            "ndcg": 0.5291745661136636
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9273648648648649,
            "recall_single_hit": 0.9273648648648649,
            "precision": 0.307713963963964,
            "map": 0.8585069444444444,
            "mrr": 0.8609938063063063,
            "ndcg": 0.8767620037977742
        },
        "Ranker": {
            "recall_multi_hit": 0.9273648648648649,
            "recall_single_hit": 0.9273648648648649,
            "precision": 0.307713963963964,
            "map": 0.8951764264264265,
            "mrr": 0.8968186936936938,
            "ndcg": 0.9039774512907163
        }
    },
    "6": {
        "BM25Retriever": {
            "recall_multi_hit": 0.9096283783783784,
            "recall_single_hit": 0.9096283783783784,
            "precision": 0.3161599099099099,
            "map": 0.8543074324324323,
            "mrr": 0.8562781531531531,
            "ndcg": 0.8691476598529074
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.6866554054054054,
            "recall_single_hit": 0.6866554054054054,
            "precision": 0.23930180180180177,
            "map": 0.5344172297297297,
            "mrr": 0.5349099099099098,
            "ndcg": 0.5738707115221078
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9510135135135135,
            "recall_single_hit": 0.9510135135135135,
            "precision": 0.20948761261261262,
            "map": 0.8590207394894894,
            "mrr": 0.8660050675675675,
            "ndcg": 0.8840576164736078
        },
        "Ranker": {
            "recall_multi_hit": 0.9510135135135135,
            "recall_single_hit": 0.9510135135135135,
            "precision": 0.20948761261261262,
            "map": 0.90849756006006,
            "mrr": 0.9135698198198199,
            "ndcg": 0.9208829795981469
        }
    },
    "7": {
        "BM25Retriever": {
            "recall_multi_hit": 0.9096283783783784,
            "recall_single_hit": 0.9096283783783784,
            "precision": 0.3161599099099099,
            "map": 0.8543074324324323,
            "mrr": 0.8562781531531531,
            "ndcg": 0.8691476598529074
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.6866554054054054,
            "recall_single_hit": 0.6866554054054054,
            "precision": 0.23930180180180177,
            "map": 0.5344172297297297,
            "mrr": 0.5349099099099098,
            "ndcg": 0.5738707115221078
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9510135135135135,
            "recall_single_hit": 0.9510135135135135,
            "precision": 0.20948761261261262,
            "map": 0.8590207394894894,
            "mrr": 0.8660050675675675,
            "ndcg": 0.8840576164736078
        },
        "Ranker": {
            "recall_multi_hit": 0.9510135135135135,
            "recall_single_hit": 0.9510135135135135,
            "precision": 0.20948761261261262,
            "map": 0.90849756006006,
            "mrr": 0.9135698198198199,
            "ndcg": 0.9208829795981469
        }
    },
    "8": {
        "BM25Retriever": {
            "recall_multi_hit": 0.9231418918918919,
            "recall_single_hit": 0.9231418918918919,
            "precision": 0.24451013513513514,
            "map": 0.8545655030030029,
            "mrr": 0.8596565315315314,
            "ndcg": 0.873462227464682
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.7449324324324325,
            "recall_single_hit": 0.7449324324324325,
            "precision": 0.19721283783783783,
            "map": 0.5479776651651652,
            "mrr": 0.5494791666666666,
            "ndcg": 0.598599051246948
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9594594594594594,
            "recall_single_hit": 0.9594594594594594,
            "precision": 0.1588994128056628,
            "map": 0.8553517803517803,
            "mrr": 0.8664404359716861,
            "ndcg": 0.8842011063392321
        },
        "Ranker": {
            "recall_multi_hit": 0.9594594594594594,
            "recall_single_hit": 0.9594594594594594,
            "precision": 0.1588994128056628,
            "map": 0.9103528193371944,
            "mrr": 0.9184262387387386,
            "ndcg": 0.9251878812275601
        }
    },
    "9": {
        "BM25Retriever": {
            "recall_multi_hit": 0.9231418918918919,
            "recall_single_hit": 0.9231418918918919,
            "precision": 0.24451013513513514,
            "map": 0.8545655030030029,
            "mrr": 0.8596565315315314,
            "ndcg": 0.873462227464682
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.7449324324324325,
            "recall_single_hit": 0.7449324324324325,
            "precision": 0.19721283783783783,
            "map": 0.5479776651651652,
            "mrr": 0.5494791666666666,
            "ndcg": 0.598599051246948
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9594594594594594,
            "recall_single_hit": 0.9594594594594594,
            "precision": 0.1588994128056628,
            "map": 0.8553517803517803,
            "mrr": 0.8664404359716861,
            "ndcg": 0.8842011063392321
        },
        "Ranker": {
            "recall_multi_hit": 0.9594594594594594,
            "recall_single_hit": 0.9594594594594594,
            "precision": 0.1588994128056628,
            "map": 0.9103528193371944,
            "mrr": 0.9184262387387386,
            "ndcg": 0.9251878812275601
        }
    },
    "10": {
        "BM25Retriever": {
            "recall_multi_hit": 0.9315878378378378,
            "recall_single_hit": 0.9315878378378378,
            "precision": 0.19932432432432431,
            "map": 0.8542816253753753,
            "mrr": 0.8613457207207208,
            "ndcg": 0.8758042937877069
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.7956081081081081,
            "recall_single_hit": 0.7956081081081081,
            "precision": 0.17094594594594592,
            "map": 0.5566382789039039,
            "mrr": 0.5596143018018018,
            "ndcg": 0.617640827232617
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9679054054054054,
            "recall_single_hit": 0.9679054054054054,
            "precision": 0.12897730319605322,
            "map": 0.8527496246246247,
            "mrr": 0.8669666318103818,
            "ndcg": 0.8848869428644325
        },
        "Ranker": {
            "recall_multi_hit": 0.9679054054054054,
            "recall_single_hit": 0.9679054054054054,
            "precision": 0.12897730319605322,
            "map": 0.911976720023595,
            "mrr": 0.9232122747747749,
            "ndcg": 0.9293609705423455
        }
    },
    "11": {
        "BM25Retriever": {
            "recall_multi_hit": 0.9315878378378378,
            "recall_single_hit": 0.9315878378378378,
            "precision": 0.19932432432432431,
            "map": 0.8542816253753753,
            "mrr": 0.8613457207207208,
            "ndcg": 0.8758042937877069
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.7956081081081081,
            "recall_single_hit": 0.7956081081081081,
            "precision": 0.17094594594594592,
            "map": 0.5566382789039039,
            "mrr": 0.5596143018018018,
            "ndcg": 0.617640827232617
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9679054054054054,
            "recall_single_hit": 0.9679054054054054,
            "precision": 0.12897730319605322,
            "map": 0.8527496246246247,
            "mrr": 0.8669666318103818,
            "ndcg": 0.8848869428644325
        },
        "Ranker": {
            "recall_multi_hit": 0.9679054054054054,
            "recall_single_hit": 0.9679054054054054,
            "precision": 0.12897730319605322,
            "map": 0.911976720023595,
            "mrr": 0.9232122747747749,
            "ndcg": 0.9293609705423455
        }
    },
    "12": {
        "BM25Retriever": {
            "recall_multi_hit": 0.933277027027027,
            "recall_single_hit": 0.933277027027027,
            "precision": 0.16708896396396397,
            "map": 0.8542781062312311,
            "mrr": 0.8616272522522522,
            "ndcg": 0.8762966226802181
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.8201013513513513,
            "recall_single_hit": 0.8201013513513513,
            "precision": 0.14864864864864866,
            "map": 0.5590362237237237,
            "mrr": 0.563696509009009,
            "ndcg": 0.6256115266971942
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9704391891891891,
            "recall_single_hit": 0.9704391891891891,
            "precision": 0.10788925085800086,
            "map": 0.8506738526269776,
            "mrr": 0.866620872089622,
            "ndcg": 0.8842076376701069
        },
        "Ranker": {
            "recall_multi_hit": 0.9704391891891891,
            "recall_single_hit": 0.9704391891891891,
            "precision": 0.10788925085800086,
            "map": 0.9114780984312234,
            "mrr": 0.9242257882882883,
            "ndcg": 0.9300309272438064
        }
    },
    "13": {
        "BM25Retriever": {
            "recall_multi_hit": 0.933277027027027,
            "recall_single_hit": 0.933277027027027,
            "precision": 0.16708896396396397,
            "map": 0.8542781062312311,
            "mrr": 0.8616272522522522,
            "ndcg": 0.8762966226802181
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.8201013513513513,
            "recall_single_hit": 0.8201013513513513,
            "precision": 0.14864864864864866,
            "map": 0.5590362237237237,
            "mrr": 0.563696509009009,
            "ndcg": 0.6256115266971942
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9704391891891891,
            "recall_single_hit": 0.9704391891891891,
            "precision": 0.10788925085800086,
            "map": 0.8506738526269776,
            "mrr": 0.866620872089622,
            "ndcg": 0.8842076376701069
        },
        "Ranker": {
            "recall_multi_hit": 0.9704391891891891,
            "recall_single_hit": 0.9704391891891891,
            "precision": 0.10788925085800086,
            "map": 0.9114780984312234,
            "mrr": 0.9242257882882883,
            "ndcg": 0.9300309272438064
        }
    },
    "14": {
        "BM25Retriever": {
            "recall_multi_hit": 0.9349662162162162,
            "recall_single_hit": 0.9349662162162162,
            "precision": 0.1449083011583011,
            "map": 0.8524669200450451,
            "mrr": 0.8618685649935649,
            "ndcg": 0.8759007084736959
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.8403716216216216,
            "recall_single_hit": 0.8403716216216216,
            "precision": 0.13151544401544396,
            "map": 0.5611851807164308,
            "mrr": 0.5665922619047619,
            "ndcg": 0.6321102439238254
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9721283783783784,
            "recall_single_hit": 0.9721283783783784,
            "precision": 0.09299997112497112,
            "map": 0.8472024204446079,
            "mrr": 0.8663636733949234,
            "ndcg": 0.8826230448505743
        },
        "Ranker": {
            "recall_multi_hit": 0.9721283783783784,
            "recall_single_hit": 0.9721283783783784,
            "precision": 0.09299997112497112,
            "map": 0.9083649296539921,
            "mrr": 0.9248391248391247,
            "ndcg": 0.929019158468138
        }
    },
    "15": {
        "BM25Retriever": {
            "recall_multi_hit": 0.9349662162162162,
            "recall_single_hit": 0.9349662162162162,
            "precision": 0.1449083011583011,
            "map": 0.8524669200450451,
            "mrr": 0.8618685649935649,
            "ndcg": 0.8759007084736959
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.8403716216216216,
            "recall_single_hit": 0.8403716216216216,
            "precision": 0.13151544401544396,
            "map": 0.5611851807164308,
            "mrr": 0.5665922619047619,
            "ndcg": 0.6321102439238254
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9721283783783784,
            "recall_single_hit": 0.9721283783783784,
            "precision": 0.09299997112497112,
            "map": 0.8472024204446079,
            "mrr": 0.8663636733949234,
            "ndcg": 0.8826230448505743
        },
        "Ranker": {
            "recall_multi_hit": 0.9721283783783784,
            "recall_single_hit": 0.9721283783783784,
            "precision": 0.09299997112497112,
            "map": 0.9083649296539921,
            "mrr": 0.9248391248391247,
            "ndcg": 0.929019158468138
        }
    },
    "16": {
        "BM25Retriever": {
            "recall_multi_hit": 0.941722972972973,
            "recall_single_hit": 0.941722972972973,
            "precision": 0.12858952702702703,
            "map": 0.8525178638459888,
            "mrr": 0.8627131595881595,
            "ndcg": 0.8776946061228414
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.856418918918919,
            "recall_single_hit": 0.856418918918919,
            "precision": 0.11782094594594594,
            "map": 0.5617857813170314,
            "mrr": 0.568598174066924,
            "ndcg": 0.6364936284708016
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9763513513513513,
            "recall_single_hit": 0.9763513513513513,
            "precision": 0.08180985329422827,
            "map": 0.8458786247458123,
            "mrr": 0.8665845204907704,
            "ndcg": 0.8828473045706065
        },
        "Ranker": {
            "recall_multi_hit": 0.9763513513513513,
            "recall_single_hit": 0.9763513513513513,
            "precision": 0.08180985329422827,
            "map": 0.9088497937716687,
            "mrr": 0.9276122104247103,
            "ndcg": 0.9310046197411421
        }
    },
    "17": {
        "BM25Retriever": {
            "recall_multi_hit": 0.941722972972973,
            "recall_single_hit": 0.941722972972973,
            "precision": 0.12858952702702703,
            "map": 0.8525178638459888,
            "mrr": 0.8627131595881595,
            "ndcg": 0.8776946061228414
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.856418918918919,
            "recall_single_hit": 0.856418918918919,
            "precision": 0.11782094594594594,
            "map": 0.5617857813170314,
            "mrr": 0.568598174066924,
            "ndcg": 0.6364936284708016
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9763513513513513,
            "recall_single_hit": 0.9763513513513513,
            "precision": 0.08180985329422827,
            "map": 0.8458786247458123,
            "mrr": 0.8665845204907704,
            "ndcg": 0.8828473045706065
        },
        "Ranker": {
            "recall_multi_hit": 0.9763513513513513,
            "recall_single_hit": 0.9763513513513513,
            "precision": 0.08180985329422827,
            "map": 0.9088497937716687,
            "mrr": 0.9276122104247103,
            "ndcg": 0.9310046197411421
        }
    },
    "18": {
        "BM25Retriever": {
            "recall_multi_hit": 0.9425675675675675,
            "recall_single_hit": 0.9425675675675675,
            "precision": 0.1156390765765766,
            "map": 0.850129286652724,
            "mrr": 0.8628070034320034,
            "ndcg": 0.8767372657186149
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.8631756756756757,
            "recall_single_hit": 0.8631756756756757,
            "precision": 0.10670045045045046,
            "map": 0.561062779137556,
            "mrr": 0.5693489248176749,
            "ndcg": 0.6378436400975174
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9763513513513513,
            "recall_single_hit": 0.9763513513513513,
            "precision": 0.07332506544363163,
            "map": 0.8430694123705547,
            "mrr": 0.8663120991245992,
            "ndcg": 0.8813006607151589
        },
        "Ranker": {
            "recall_multi_hit": 0.9763513513513513,
            "recall_single_hit": 0.9763513513513513,
            "precision": 0.07332506544363163,
            "map": 0.9057755244280322,
            "mrr": 0.9268379987129987,
            "ndcg": 0.9293188457144039
        }
    },
    "19": {
        "BM25Retriever": {
            "recall_multi_hit": 0.9425675675675675,
            "recall_single_hit": 0.9425675675675675,
            "precision": 0.1156390765765766,
            "map": 0.850129286652724,
            "mrr": 0.8628070034320034,
            "ndcg": 0.8767372657186149
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.8631756756756757,
            "recall_single_hit": 0.8631756756756757,
            "precision": 0.10670045045045046,
            "map": 0.561062779137556,
            "mrr": 0.5693489248176749,
            "ndcg": 0.6378436400975174
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9763513513513513,
            "recall_single_hit": 0.9763513513513513,
            "precision": 0.07332506544363163,
            "map": 0.8430694123705547,
            "mrr": 0.8663120991245992,
            "ndcg": 0.8813006607151589
        },
        "Ranker": {
            "recall_multi_hit": 0.9763513513513513,
            "recall_single_hit": 0.9763513513513513,
            "precision": 0.07332506544363163,
            "map": 0.9057755244280322,
            "mrr": 0.9268379987129987,
            "ndcg": 0.9293188457144039
        }
    },
    "20": {
        "BM25Retriever": {
            "recall_multi_hit": 0.9459459459459459,
            "recall_single_hit": 0.9459459459459459,
            "precision": 0.10511918168168168,
            "map": 0.8489142099688973,
            "mrr": 0.8631448412698413,
            "ndcg": 0.8769558643353698
        },
        "DenseRetriever": {
            "recall_multi_hit": 0.870777027027027,
            "recall_single_hit": 0.870777027027027,
            "precision": 0.09712837837837837,
            "map": 0.5613187047059814,
            "mrr": 0.57010905995281,
            "ndcg": 0.6398314069155374
        },
        "JoinDocuments": {
            "recall_multi_hit": 0.9771959459459459,
            "recall_single_hit": 0.9771959459459459,
            "precision": 0.06615384659719992,
            "map": 0.8410085531812644,
            "mrr": 0.8661814469077916,
            "ndcg": 0.880329146952571
        },
        "Ranker": {
            "recall_multi_hit": 0.9771959459459459,
            "recall_single_hit": 0.9771959459459459,
            "precision": 0.06615384659719992,
            "map": 0.9038610402300246,
            "mrr": 0.9275548986486486,
            "ndcg": 0.9286756306557109
        }
    }
}